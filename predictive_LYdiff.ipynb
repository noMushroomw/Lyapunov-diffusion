{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd1f265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: imports and utils\n",
    "import math, os, time, json, random\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets, transforms, utils as tvu\n",
    "\n",
    "try:\n",
    "    import torch_fidelity\n",
    "    HAS_TORCH_FIDELITY = True\n",
    "except Exception:\n",
    "    HAS_TORCH_FIDELITY = False\n",
    "\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED); np.random.seed(SEED); random.seed(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def count_params(m: nn.Module):\n",
    "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "\n",
    "def to_device(x, device):\n",
    "    return x.to(device, non_blocking=True)\n",
    "\n",
    "def set_requires_grad(m: nn.Module, flag: bool):\n",
    "    for p in m.parameters():\n",
    "        p.requires_grad = flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecab0b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: CIFAR-10 dataloader\n",
    "def get_cifar10(batch_size=256, num_workers=4, root=\"./data\"):\n",
    "    tfm = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: x*2.0 - 1.0),  # [-1, 1]\n",
    "    ])\n",
    "    train = datasets.CIFAR10(root=root, train=True, transform=tfm, download=True)\n",
    "    test  = datasets.CIFAR10(root=root, train=False, transform=tfm, download=True)\n",
    "    train_loader = data.DataLoader(train, batch_size=batch_size, shuffle=True,\n",
    "                                   num_workers=num_workers, pin_memory=True, drop_last=True)\n",
    "    test_loader  = data.DataLoader(test,  batch_size=batch_size, shuffle=False,\n",
    "                                   num_workers=num_workers, pin_memory=True, drop_last=False)\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42185094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: embeddings and predictive-coding core (bug-fixed)\n",
    "\n",
    "class GaussianFourierProjection(nn.Module):\n",
    "    \"\"\"Gaussian Fourier features of log(sigma).\"\"\"\n",
    "    def __init__(self, emb_dim=128, scale=16.0):\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.randn(emb_dim//2) * scale, requires_grad=False)\n",
    "\n",
    "    def forward(self, sigma):  # sigma: (B,)\n",
    "        # Use log-sigma for better conditioning\n",
    "        x = sigma.clamp(min=1e-8).log().unsqueeze(-1)  # (B,1)\n",
    "        f = x * self.W.view(1, -1)                    # (B, emb_dim//2)\n",
    "        return torch.cat([f.sin(), f.cos()], dim=-1)  # (B, emb_dim)\n",
    "\n",
    "class MLPFiLM(nn.Module):\n",
    "    \"\"\"Embed -> scale, shift for FiLM-like conditioning.\"\"\"\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, out_dim*2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(out_dim*2, out_dim*2),\n",
    "        )\n",
    "    def forward(self, emb):  # (B, E) -> (B, 2*C)\n",
    "        return self.net(emb)\n",
    "\n",
    "class PCBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Predictive-coding update:\n",
    "      state s (C,H,W)\n",
    "      target features f (C,H,W)\n",
    "      error e = f - s in the SAME channel space\n",
    "      delta = g([s, e]) with FiLM from embedding, then s <- s + delta\n",
    "    \"\"\"\n",
    "    def __init__(self, C, emb_dim, groups=16):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.GroupNorm(groups, 2*C)\n",
    "        self.conv1 = nn.Conv2d(2*C, C, 3, padding=1)\n",
    "        self.norm2 = nn.GroupNorm(groups, C)\n",
    "        self.conv2 = nn.Conv2d(C, C, 3, padding=1)\n",
    "        self.emb_proj = MLPFiLM(emb_dim, C)\n",
    "\n",
    "    def forward(self, s, f, emb):\n",
    "        # s, f: (B,C,H,W); emb: (B,E)\n",
    "        e = f - s\n",
    "        x = torch.cat([s, e], dim=1)\n",
    "        x = self.conv1(self.norm1(x))\n",
    "        x = F.silu(x)\n",
    "        # FiLM\n",
    "        gamma, beta = self.emb_proj(emb).chunk(2, dim=1)  # (B,C), (B,C)\n",
    "        gamma = gamma.unsqueeze(-1).unsqueeze(-1)\n",
    "        beta  = beta.unsqueeze(-1).unsqueeze(-1)\n",
    "        x = self.norm2(x) * (1 + gamma) + beta\n",
    "        x = F.silu(x)\n",
    "        delta = self.conv2(x)\n",
    "        return s + delta\n",
    "\n",
    "class PredictiveCodingCore(nn.Module):\n",
    "    \"\"\"\n",
    "    Core: project RGB to C, run K PC blocks with shared target features f,\n",
    "    then project back to RGB.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch=3, C=128, K=8, emb_dim=128, groups=16):\n",
    "        super().__init__()\n",
    "        self.in_proj  = nn.Conv2d(in_ch, C, 3, padding=1)\n",
    "        self.blocks   = nn.ModuleList([PCBlock(C, emb_dim, groups=groups) for _ in range(K)])\n",
    "        self.out_norm = nn.GroupNorm(groups, C)\n",
    "        self.out_proj = nn.Conv2d(C, in_ch, 3, padding=1)\n",
    "\n",
    "    def forward(self, x_cond, emb):\n",
    "        # x_cond: preconditioned noisy input in RGB; emb: (B,E)\n",
    "        f = self.in_proj(x_cond)        # target features\n",
    "        s = f.clone()                   # predictive state starts equal to target projection\n",
    "        for blk in self.blocks:\n",
    "            s = blk(s, f, emb)\n",
    "        y = self.out_proj(F.silu(self.out_norm(s)))\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a870f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- EDM config (CIFAR-10) ---\n",
    "class EDMConfig:\n",
    "    sigma_data = 0.5\n",
    "    sigma_min  = 0.002\n",
    "    sigma_max  = 80.0\n",
    "    rho        = 7.0\n",
    "    P_mean     = -1.2\n",
    "    P_std      =  1.2\n",
    "\n",
    "cfg = EDMConfig()\n",
    "\n",
    "# --- sinusoidal embedding for log-sigma ---\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, in_dim=1, hidden=256, out_dim=256):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden), nn.SiLU(),\n",
    "            nn.Linear(hidden, out_dim), nn.SiLU()\n",
    "        )\n",
    "    def forward(self, log_sigma):  # log_sigma shape: (B, 1)\n",
    "        return self.mlp(log_sigma)\n",
    "\n",
    "# --- EDM coeffs ---\n",
    "def edm_coeffs(sigma, sigma_data=0.5):\n",
    "    # sigma: (B,1,1,1)\n",
    "    s2 = sigma * sigma\n",
    "    sd2 = sigma_data * sigma_data\n",
    "    denom = torch.sqrt(s2 + sd2)\n",
    "    c_in   = 1.0 / denom\n",
    "    c_out  = (sigma * sigma_data) / denom\n",
    "    c_skip = sd2 / (s2 + sd2)\n",
    "    return c_skip, c_out, c_in\n",
    "\n",
    "# --- Your predictive-coding core is used as the raw network F_theta ---\n",
    "# It must map (x_in, x_hat0_init, emb) -> residual in data space.\n",
    "# It should return a CxHxW tensor per example.\n",
    "# (Keep your existing PredictiveCodingCore / PCBlock definitions.)\n",
    "# Example: core = PredictiveCodingCore(C=3, width=128, ...)\n",
    "\n",
    "class DenoiserEDM(nn.Module):\n",
    "    def __init__(self, core, emb_dim=256):\n",
    "        super().__init__()\n",
    "        self.core = core\n",
    "        self.t_embed = TimeEmbedding(in_dim=1, hidden=512, out_dim=emb_dim)\n",
    "\n",
    "    def forward(self, x, sigma_scalar):\n",
    "        \"\"\"\n",
    "        x: (B,C,H,W), sigma_scalar: (B,)   -> returns x_hat0 (B,C,H,W)\n",
    "        \"\"\"\n",
    "        B = x.shape[0]\n",
    "        sigma_4d = sigma_scalar.view(B, 1, 1, 1)\n",
    "        log_sigma = 0.25 * torch.log(sigma_scalar).view(B, 1)  # cnoise(σ)=¼ log σ\n",
    "        emb = self.t_embed(log_sigma)  # (B,emb_dim)\n",
    "\n",
    "        c_skip, c_out, c_in = edm_coeffs(sigma_4d, cfg.sigma_data)  # (B,1,1,1)\n",
    "        x_in = c_in * x\n",
    "\n",
    "        # Your core takes (x_in, x_hat0_init, emb). Keep zeros as x_hat0_init.\n",
    "        h = self.core(x_in, torch.zeros_like(x_in), emb)  # raw prediction in data space\n",
    "\n",
    "        # Preconditioning wrapper: x_hat0 = c_skip * x + c_out * h\n",
    "        x_hat0 = c_skip * x + c_out * h\n",
    "        return x_hat0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f61b0e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: training utilities\n",
    "\n",
    "@dataclass\n",
    "class TrainCfg:\n",
    "    lr: float = 2e-4\n",
    "    wd: float = 0.0\n",
    "    epochs: int = 300\n",
    "    batch_size: int = 256\n",
    "    num_workers: int = 4\n",
    "    sigma_min: float = 0.002\n",
    "    sigma_max: float = 80.0\n",
    "    rho: float = 7.0\n",
    "    sigma_data: float = 0.5\n",
    "    ema_decay: float = 0.999\n",
    "    amp: bool = True\n",
    "    ckpt_dir: str = \"./pc_edm_ckpts\"\n",
    "\n",
    "class EMA:\n",
    "    def __init__(self, m: nn.Module, decay=0.999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {k: v.detach().clone() for k, v in m.state_dict().items()}\n",
    "    @torch.no_grad()\n",
    "    def update(self, m: nn.Module):\n",
    "        for k, v in m.state_dict().items():\n",
    "            self.shadow[k].mul_(self.decay).add_(v.detach(), alpha=1.0 - self.decay)\n",
    "    @torch.no_grad()\n",
    "    def copy_to(self, m: nn.Module):\n",
    "        m.load_state_dict(self.shadow, strict=True)\n",
    "\n",
    "def sample_log_uniform_sigma(bsz, sigma_min, sigma_max, device):\n",
    "    u = torch.rand(bsz, device=device)\n",
    "    return (sigma_min**2 * (sigma_max**2 / sigma_min**2) ** u).sqrt()\n",
    "\n",
    "def mse_loss(x, y, reduction='mean'):\n",
    "    return F.mse_loss(x, y, reduction=reduction)\n",
    "\n",
    "def train_one_epoch(model, opt, ema, loader, cfg: TrainCfg, device):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=cfg.amp)\n",
    "    loss_meter = 0.0\n",
    "    n = 0\n",
    "    for x, _ in loader:\n",
    "        x = to_device(x, device)\n",
    "        b = x.size(0)\n",
    "        sigma = sample_log_uniform_sigma(b, cfg.sigma_min, cfg.sigma_max, x.device)\n",
    "        noise = torch.randn_like(x)\n",
    "        x_noisy = x + sigma.view(b,1,1,1) * noise\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=cfg.amp):\n",
    "            x_hat = model(x_noisy, sigma)        # predict x0\n",
    "            # Plain L2 in x-space (EDM often uses simple L2 with log-uniform sigma sampling)\n",
    "            loss = mse_loss(x_hat, x)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(opt)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "        ema.update(model)\n",
    "\n",
    "        loss_meter += loss.item() * b\n",
    "        n += b\n",
    "    return loss_meter / max(1, n)\n",
    "\n",
    "def save_ckpt(model, ema, opt, epoch, cfg: TrainCfg):\n",
    "    Path(cfg.ckpt_dir).mkdir(parents=True, exist_ok=True)\n",
    "    ckpt = {\n",
    "        'model': model.state_dict(),\n",
    "        'ema': ema.shadow,\n",
    "        'opt': opt.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'cfg': cfg.__dict__,\n",
    "    }\n",
    "    torch.save(ckpt, Path(cfg.ckpt_dir)/f\"epoch_{epoch:04d}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e85b42f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: EDM Heun sampler (Karras schedule)\n",
    "\n",
    "@torch.no_grad()\n",
    "def karras_sigmas(n, sigma_min, sigma_max, rho, device):\n",
    "    # Decreasing schedule with Heun; append final 0 as last node\n",
    "    i = torch.arange(n, device=device, dtype=torch.float32)\n",
    "    ramp = i / (n - 1)\n",
    "    min_inv_rho = sigma_min ** (1.0 / rho)\n",
    "    max_inv_rho = sigma_max ** (1.0 / rho)\n",
    "    sigmas = (max_inv_rho + ramp * (min_inv_rho - max_inv_rho)) ** rho\n",
    "    sigmas = torch.cat([sigmas, torch.zeros_like(sigmas[:1])], dim=0)  # add zero\n",
    "    return sigmas  # shape: (n+1,)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def heun_sampler(denoiser, batch_size, channels, height, width,\n",
    "                 steps=40, sigma_min=None, sigma_max=None, rho=None, device='cuda'):\n",
    "    sigma_min = cfg.sigma_min if sigma_min is None else sigma_min\n",
    "    sigma_max = cfg.sigma_max if sigma_max is None else sigma_max\n",
    "    rho       = cfg.rho       if rho is None else rho\n",
    "\n",
    "    sigmas = karras_sigmas(steps, sigma_min, sigma_max, rho, device)  # (steps+1,)\n",
    "    # Start from N(0, sigma_max^2 I)\n",
    "    x = torch.randn(batch_size, channels, height, width, device=device) * sigmas[0]\n",
    "\n",
    "    for i in range(steps):\n",
    "        s_i = sigmas[i].expand(batch_size)      # (B,)\n",
    "        s_j = sigmas[i+1].expand(batch_size)    # (B,)\n",
    "\n",
    "        # First slope di = (x - x_hat0)/σi\n",
    "        x_hat0_i = denoiser(x, s_i)             # (B,C,H,W)\n",
    "        di = (x - x_hat0_i) / s_i.view(-1,1,1,1)\n",
    "\n",
    "        # Euler step\n",
    "        dt = (s_j - s_i).view(-1,1,1,1)         # (B,1,1,1), negative\n",
    "        x_euler = x + dt * di\n",
    "\n",
    "        # Second slope dj at provisional state\n",
    "        x_hat0_j = denoiser(x_euler, s_j)\n",
    "        dj = (x_euler - x_hat0_j) / s_j.view(-1,1,1,1)\n",
    "\n",
    "        # Heun update\n",
    "        x = x + dt * 0.5 * (di + dj)\n",
    "\n",
    "    return x.clamp(-1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe87f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: FID evaluation (requires torch-fidelity)\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_cifar10_samples(denoiser, n_samples=50000, batch=250, device='cuda',\n",
    "                             steps=40, sigma_min=0.002, sigma_max=80.0, rho=7.0):\n",
    "    denoiser.eval()\n",
    "    imgs = []\n",
    "    n_batches = (n_samples + batch - 1) // batch\n",
    "    for _ in range(n_batches):\n",
    "        b = min(batch, n_samples - len(imgs))\n",
    "        x = heun_sampler(denoiser, b, 3, 32, 32, steps=steps,\n",
    "                         sigma_min=sigma_min, sigma_max=sigma_max, rho=rho, device=device)\n",
    "        # to [0,1]\n",
    "        x = (x + 1.0) * 0.5\n",
    "        imgs.append(x.cpu())\n",
    "    return torch.cat(imgs, dim=0)[:n_samples]\n",
    "\n",
    "def save_images_tensor(imgs, out_dir):\n",
    "    out = Path(out_dir)\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "    for i in range(imgs.size(0)):\n",
    "        tvu.save_image(imgs[i], out/f\"{i:06d}.png\")\n",
    "\n",
    "def compute_fid_with_torch_fidelity(gen_dir, ref_dataset='cifar10-train'):\n",
    "    assert HAS_TORCH_FIDELITY, \"torch-fidelity not available.\"\n",
    "    metrics = torch_fidelity.calculate_metrics(\n",
    "        input1=str(gen_dir),\n",
    "        input2=ref_dataset,   # 'cifar10-train' or 'cifar10-test'\n",
    "        fid=True, verbose=False)\n",
    "    return float(metrics['frechet_inception_distance'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bca1fea",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DenoiserEDM.__init__() got an unexpected keyword argument 'sigma_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m cfg \u001b[38;5;241m=\u001b[39m TrainCfg()\n\u001b[1;32m      5\u001b[0m core \u001b[38;5;241m=\u001b[39m PredictiveCodingCore(in_ch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m192\u001b[39m, K\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, emb_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m denoiser \u001b[38;5;241m=\u001b[39m \u001b[43mDenoiserEDM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigma_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams (M):\u001b[39m\u001b[38;5;124m\"\u001b[39m, count_params(denoiser)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1e6\u001b[39m)\n\u001b[1;32m      9\u001b[0m opt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(denoiser\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mwd, betas\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0.999\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: DenoiserEDM.__init__() got an unexpected keyword argument 'sigma_data'"
     ]
    }
   ],
   "source": [
    "# Cell 8: build model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "cfg = TrainCfg()\n",
    "\n",
    "core = PredictiveCodingCore(in_ch=3, C=192, K=10, emb_dim=128, groups=32)\n",
    "denoiser = DenoiserEDM(core=core, sigma_data=cfg.sigma_data, emb_dim=128).to(device)\n",
    "print(\"Params (M):\", count_params(denoiser)/1e6)\n",
    "\n",
    "opt = torch.optim.AdamW(denoiser.parameters(), lr=cfg.lr, weight_decay=cfg.wd, betas=(0.9, 0.999))\n",
    "ema = EMA(denoiser, decay=cfg.ema_decay)\n",
    "\n",
    "train_loader, test_loader = get_cifar10(batch_size=cfg.batch_size, num_workers=cfg.num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2112f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edm_loss(denoiser, x0):\n",
    "    \"\"\"\n",
    "    x0 in [-1,1]. Draw sigma ~ LogNormal(P_mean, P_std), add noise,\n",
    "    weight MSE by lambda(sigma) = (σ²+σd²)/(σ² σd²).\n",
    "    \"\"\"\n",
    "    B = x0.shape[0]\n",
    "    device = x0.device\n",
    "    # sample log-sigma\n",
    "    rnd = torch.randn(B, device=device) * cfg.P_std + cfg.P_mean\n",
    "    sigma = rnd.exp()  # (B,)\n",
    "\n",
    "    n = torch.randn_like(x0)\n",
    "    x_sigma = x0 + sigma.view(B,1,1,1) * n\n",
    "\n",
    "    # weighted MSE to x0\n",
    "    x_hat0 = denoiser(x_sigma, sigma)\n",
    "    lam = (sigma*sigma + cfg.sigma_data*cfg.sigma_data) / ((sigma * cfg.sigma_data)**2)  # (B,)\n",
    "    w = lam.view(B,1,1,1)\n",
    "    return (w * (x_hat0 - x0)**2).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab2284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv, torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- data to [-1,1] ---\n",
    "transform = T.Compose([T.ToTensor(), T.Lambda(lambda z: z*2.0 - 1.0)])\n",
    "trainset = tv.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "\n",
    "# --- model, opt, ema ---\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "core = PredictiveCodingCore(...)  # keep your PC architecture\n",
    "denoiser = DenoiserEDM(core).to(device)\n",
    "\n",
    "opt = torch.optim.AdamW(denoiser.parameters(), lr=2e-4, betas=(0.9, 0.99), weight_decay=0.0)\n",
    "# EMA\n",
    "class EMA:\n",
    "    def __init__(self, model, decay=0.9999):\n",
    "        self.decay = decay\n",
    "        self.shadow = [p.detach().clone() for p in model.parameters() if p.requires_grad]\n",
    "        self.params = [p for p in model.parameters() if p.requires_grad]\n",
    "    @torch.no_grad()\n",
    "    def update(self):\n",
    "        for s, p in zip(self.shadow, self.params):\n",
    "            s.mul_(self.decay).add_(p.detach(), alpha=(1.0 - self.decay))\n",
    "    @torch.no_grad()\n",
    "    def copy_to(self, model):\n",
    "        for s, p in zip(self.shadow, self.params):\n",
    "            p.data.copy_(s.data)\n",
    "\n",
    "ema = EMA(denoiser, decay=0.9999)\n",
    "\n",
    "# --- training ---\n",
    "def train_edm_pc(denoiser, loader, epochs=50):\n",
    "    denoiser.train()\n",
    "    for ep in range(1, epochs+1):\n",
    "        tot = 0.0\n",
    "        for x,_ in loader:\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            loss = edm_loss(denoiser, x)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(denoiser.parameters(), 1.0)\n",
    "            opt.step()\n",
    "            ema.update()\n",
    "            tot += loss.item()\n",
    "        print(f\"epoch {ep:04d} | loss {tot/len(loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed828a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: quick graph/sanity check (8 samples)\n",
    "ema.copy_to(denoiser)\n",
    "with torch.no_grad():\n",
    "    imgs = heun_sampler(denoiser, batch_size=8, channels=3, height=32, width=32,\n",
    "                        steps=40, sigma_min=cfg.sigma_min, sigma_max=cfg.sigma_max, rho=cfg.rho, device=device)\n",
    "grid = tvu.make_grid((imgs+1)*0.5, nrow=4)\n",
    "display(transforms.ToPILImage()(grid.cpu()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf85e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after some training:\n",
    "ema.copy_to(denoiser)  # swap in EMA weights\n",
    "denoiser.eval()\n",
    "with torch.no_grad():\n",
    "    imgs = heun_sampler(denoiser, batch_size=8, channels=3, height=32, width=32,\n",
    "                        steps=40, sigma_min=cfg.sigma_min, sigma_max=cfg.sigma_max,\n",
    "                        rho=cfg.rho, device=device)\n",
    "# de-normalize for display\n",
    "grid = tv.utils.make_grid((imgs + 1)/2, nrow=4, padding=2)\n",
    "T.ToPILImage()(grid.cpu()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1884d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torchmetrics torchvision\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "def fid_from_sampler(denoiser, n_gen=5000, batch=100, steps=40):\n",
    "    fid = FrechetInceptionDistance(feature=2048, normalize=True).to(device)\n",
    "    # real stats\n",
    "    for x,_ in DataLoader(trainset, batch_size=batch, shuffle=True):\n",
    "        x = x.to(device)\n",
    "        fid.update(((x+1)/2).clamp(0,1), real=True)\n",
    "        if fid.real_features_num >= n_gen: break\n",
    "    # fake stats\n",
    "    ema.copy_to(denoiser); denoiser.eval()\n",
    "    done = 0\n",
    "    while done < n_gen:\n",
    "        bs = min(batch, n_gen - done)\n",
    "        imgs = heun_sampler(denoiser, batch_size=bs, channels=3, height=32, width=32, steps=steps, device=device)\n",
    "        fid.update(((imgs+1)/2).clamp(0,1), real=False)\n",
    "        done += bs\n",
    "    return float(fid.compute().cpu())\n",
    "\n",
    "print(\"Approx FID:\", fid_from_sampler(denoiser, n_gen=10000, batch=100, steps=40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671f32cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: FID (needs time and disk)\n",
    "ema.copy_to(denoiser)\n",
    "gen_dir = \"./gen_cifar10\"\n",
    "samples = generate_cifar10_samples(denoiser, n_samples=50000, batch=250, device=device,\n",
    "                                   steps=40, sigma_min=cfg.sigma_min, sigma_max=cfg.sigma_max, rho=cfg.rho)\n",
    "save_images_tensor(samples, gen_dir)\n",
    "if HAS_TORCH_FIDELITY:\n",
    "    fid = compute_fid_with_torch_fidelity(gen_dir, ref_dataset='cifar10-train')\n",
    "    print(\"FID (vs CIFAR-10 train):\", fid)\n",
    "else:\n",
    "    print(\"Install torch-fidelity to compute FID, or use pytorch-fid.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d046c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
