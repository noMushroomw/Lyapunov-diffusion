{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a92c369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu128\n",
      "CUDA available: True\n",
      "Using device: cuda:2\n",
      "GPU Name: NVIDIA B200\n",
      "âœ… Imports successful.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import Libraries & Setup Device\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch_ema import ExponentialMovingAverage\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import math\n",
    "from PIL import Image\n",
    "from cleanfid.fid import compute_fid\n",
    "\n",
    "# Health Check\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "print(\"âœ… Imports successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c67b5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining the CORRECT EDM model architecture (NCSNpp)...\n",
      "\n",
      "--- Health Check ---\n",
      "âœ… Model forward pass successful.\n",
      "Input shape: torch.Size([2, 3, 32, 32]), Output shape: torch.Size([2, 3, 32, 32])\n",
      "Model parameters: 39,852,547\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: CORRECT EDM Model Architecture (NCSNpp)\n",
    "# This is the Karras et al. (2022) model. It is correct.\n",
    "\n",
    "print(\"Defining the CORRECT EDM model architecture (NCSNpp)...\")\n",
    "\n",
    "class ResBlock(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        emb_channels,\n",
    "        dropout,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.emb_channels = emb_channels\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Main path\n",
    "        self.norm1 = torch.nn.GroupNorm(num_groups=min(32, in_channels), num_channels=in_channels, eps=1e-5)\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Embedding projection\n",
    "        self.emb_proj = torch.nn.Linear(emb_channels, out_channels)\n",
    "        \n",
    "        # Second part of main path\n",
    "        self.norm2 = torch.nn.GroupNorm(num_groups=min(32, out_channels), num_channels=out_channels, eps=1e-5)\n",
    "        self.conv2 = torch.nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Skip connection\n",
    "        self.skip = torch.nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False) if in_channels != out_channels else torch.nn.Identity()\n",
    "\n",
    "    def forward(self, x, emb):\n",
    "        h = self.skip(x) # Save skip connection\n",
    "        \n",
    "        # First block\n",
    "        x = self.norm1(x)\n",
    "        x = torch.nn.functional.silu(x)\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        # Add time embedding\n",
    "        emb_out = self.emb_proj(torch.nn.functional.silu(emb))\n",
    "        x = x + emb_out.unsqueeze(-1).unsqueeze(-1)\n",
    "        \n",
    "        # Second block\n",
    "        x = self.norm2(x)\n",
    "        x = torch.nn.functional.silu(x)\n",
    "        x = torch.nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        # Final skip\n",
    "        return x + h, emb\n",
    "\n",
    "class AttentionBlock(torch.nn.Module):\n",
    "    def __init__(self, num_channels, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.num_heads = num_heads\n",
    "        self.norm = torch.nn.GroupNorm(num_groups=min(32, num_channels), num_channels=num_channels, eps=1e-5)\n",
    "        self.qkv = torch.nn.Conv2d(num_channels, num_channels * 3, kernel_size=1)\n",
    "        self.proj = torch.nn.Conv2d(num_channels, num_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x, emb):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.qkv(self.norm(x))\n",
    "        qkv = qkv.reshape(b, 3, self.num_heads, c // self.num_heads, h * w)\n",
    "        qkv = qkv.permute(1, 0, 2, 4, 3)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        out = torch.nn.functional.scaled_dot_product_attention(q, k, v)\n",
    "        out = out.permute(0, 1, 3, 2).reshape(b, c, h, w)\n",
    "        return x + self.proj(out), emb\n",
    "\n",
    "class Upsample(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class Downsample(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class PositionalEmbedding(torch.nn.Module):\n",
    "    def __init__(self, num_channels, max_positions=10000, endpoint=False):\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.max_positions = max_positions\n",
    "        self.endpoint = endpoint\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x.ndim == 0:\n",
    "            x = x.unsqueeze(0)\n",
    "        freqs = torch.arange(start=0, end=self.num_channels//2, dtype=torch.float32, device=x.device)\n",
    "        freqs = freqs / (self.num_channels // 2 - (1 if self.endpoint else 0))\n",
    "        freqs = (1 / self.max_positions) ** freqs\n",
    "        x = x.ger(freqs.to(x.dtype))\n",
    "        x = torch.cat([x.cos(), x.sin()], dim=1)\n",
    "        return x\n",
    "\n",
    "class SongUNet(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        img_resolution,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        model_channels      = 128,\n",
    "        channel_mult        = [1, 2, 2, 2],\n",
    "        channel_mult_emb    = 4,\n",
    "        num_blocks          = 4,\n",
    "        attn_resolutions    = [16],\n",
    "        dropout             = 0.10,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.img_resolution = img_resolution\n",
    "        emb_channels = model_channels * channel_mult_emb\n",
    "        \n",
    "        self.embed = torch.nn.Sequential(\n",
    "            PositionalEmbedding(num_channels=model_channels, max_positions=10000),\n",
    "            torch.nn.Linear(model_channels, emb_channels),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(emb_channels, emb_channels),\n",
    "        )\n",
    "        \n",
    "        self.blocks = torch.nn.ModuleList()\n",
    "        in_ch = in_channels\n",
    "        current_res = img_resolution\n",
    "        \n",
    "        self.blocks.append(torch.nn.Conv2d(in_ch, model_channels, kernel_size=3, padding=1))\n",
    "        in_ch = model_channels\n",
    "        current_res = img_resolution\n",
    "        \n",
    "        for level, mult in enumerate(channel_mult):\n",
    "            out_ch = model_channels * mult\n",
    "            \n",
    "            if level > 0:\n",
    "                self.blocks.append(Downsample(in_channels=in_ch, out_channels=in_ch))\n",
    "                current_res //= 2\n",
    "            \n",
    "            for _ in range(num_blocks):\n",
    "                self.blocks.append(ResBlock(in_channels=in_ch, out_channels=out_ch,\n",
    "                                            emb_channels=emb_channels, dropout=dropout))\n",
    "                in_ch = out_ch\n",
    "                if current_res in attn_resolutions:\n",
    "                    self.blocks.append(AttentionBlock(num_channels=out_ch))\n",
    "        \n",
    "        for level, mult in reversed(list(enumerate(channel_mult))):\n",
    "            out_ch = model_channels * mult\n",
    "            \n",
    "            for _ in range(num_blocks):\n",
    "                self.blocks.append(ResBlock(in_channels=in_ch, out_channels=out_ch,\n",
    "                                            emb_channels=emb_channels, dropout=dropout))\n",
    "                in_ch = out_ch\n",
    "                if current_res in attn_resolutions:\n",
    "                    self.blocks.append(AttentionBlock(num_channels=out_ch))\n",
    "            \n",
    "            if level > 0:\n",
    "                self.blocks.append(Upsample(in_channels=in_ch, out_channels=in_ch))\n",
    "                current_res *= 2\n",
    "        \n",
    "        self.out = torch.nn.Sequential(\n",
    "            torch.nn.GroupNorm(num_groups=min(32, in_ch), num_channels=in_ch, eps=1e-5),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Conv2d(in_channels=in_ch, out_channels=out_channels, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, c_noise):\n",
    "        emb = self.embed(c_noise)\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            if isinstance(block, (ResBlock, AttentionBlock)):\n",
    "                x, emb = block(x, emb)\n",
    "            else:\n",
    "                x = block(x)\n",
    "        \n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "# --- Health Check ---\n",
    "print(\"\\n--- Health Check ---\")\n",
    "try:\n",
    "    test_model = SongUNet(img_resolution=32, in_channels=3, out_channels=3).to(device)\n",
    "    test_batch = torch.randn(2, 3, 32, 32).to(device)\n",
    "    # Test with a BATCH of noise embeddings\n",
    "    test_noise = torch.tensor([1.0, 0.5], device=device).log() / 4.0\n",
    "    output = test_model(test_batch, test_noise)\n",
    "    print(f\"âœ… Model forward pass successful.\")\n",
    "    print(f\"Input shape: {test_batch.shape}, Output shape: {output.shape}\")\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in test_model.parameters()):,}\")\n",
    "    del test_model, test_batch, test_noise, output\n",
    "    torch.cuda.empty_cache()\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Model test pass FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca59b86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 50000\n",
      "Number of batches: 391\n",
      "Batch shape: torch.Size([128, 3, 32, 32])\n",
      "Data range: [-1.00, 1.00]\n",
      "âœ… Dataloader ready.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Dataloader (CIFAR-10)\n",
    "BATCH_SIZE = 128\n",
    "DATA_ROOT = './data'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(\n",
    "    root=DATA_ROOT,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "# Health Check\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of batches: {len(train_loader)}\")\n",
    "x_batch, y_batch = next(iter(train_loader))\n",
    "print(f\"Batch shape: {x_batch.shape}\")\n",
    "print(f\"Data range: [{x_batch.min():.2f}, {x_batch.max():.2f}]\")\n",
    "print(\"âœ… Dataloader ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcf02b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loss function test: 0.3834\n",
      "\n",
      "ðŸ“Š Noise distribution (P_std=1.6):\n",
      "  Mean Ïƒ: 1.102\n",
      "  99th percentile: 12.994\n",
      "  % with Ïƒ > 80: 0.02%\n",
      "  âœ… Good coverage for Ïƒ_max=80!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: EDM Loss Function (FIXED)\n",
    "\n",
    "# P_std = 1.6 is correct (matches user's fix)\n",
    "P_mean = -1.2\n",
    "P_std = 1.6\n",
    "\n",
    "def loss_fn(model, x_0):\n",
    "    \"\"\"\n",
    "    EDM denoising score matching loss.\n",
    "    \"\"\"\n",
    "    # Sample sigma ~ LogNormal(P_mean, P_std)\n",
    "    rnd_normal = torch.randn(x_0.shape[0], device=x_0.device)\n",
    "    sigma = (rnd_normal * P_std + P_mean).exp()\n",
    "    sigma = sigma.view(-1, 1, 1, 1)\n",
    "    \n",
    "    # Add noise\n",
    "    n = torch.randn_like(x_0)\n",
    "    x_sigma = x_0 + sigma * n\n",
    "    \n",
    "    # EDM Preconditioning (These constants define the VP objective)\n",
    "    c_skip = 1.0 / (sigma ** 2 + 1.0)\n",
    "    c_out = sigma / (sigma ** 2 + 1.0).sqrt()\n",
    "    c_in = 1.0 / (sigma ** 2 + 1.0).sqrt()\n",
    "    c_noise = sigma.log() / 4\n",
    "    \n",
    "    # Forward pass\n",
    "    F_x = model(c_in * x_sigma, c_noise.squeeze())\n",
    "    D_theta = c_skip * x_sigma + c_out * F_x\n",
    "    \n",
    "    # --- ðŸ›‘ BUG FIX #1 ðŸ›‘ ---\n",
    "    # The loss weight lambda(sigma) for the VP formulation is 1.0\n",
    "    # Your old code used c_skip**2, which was incorrect.\n",
    "    loss_weight = 1.0\n",
    "    # --- End of Fix ---\n",
    "    \n",
    "    loss = loss_weight * ((D_theta - x_0) ** 2)\n",
    "    \n",
    "    return loss.mean()\n",
    "\n",
    "# Test\n",
    "try:\n",
    "    test_model = SongUNet(img_resolution=32, in_channels=3, out_channels=3).to(device)\n",
    "    test_batch = torch.randn(4, 3, 32, 32).to(device)\n",
    "    test_loss = loss_fn(test_model, test_batch)\n",
    "    print(f\"âœ… Loss function test: {test_loss.item():.4f}\")\n",
    "    del test_model, test_batch, test_loss\n",
    "    torch.cuda.empty_cache()\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Loss function test FAILED: {e}\")\n",
    "\n",
    "# Show distribution coverage\n",
    "print(f\"\\nðŸ“Š Noise distribution (P_std={P_std}):\")\n",
    "rnd = torch.randn(100000)\n",
    "sigma_dist = (rnd * P_std + P_mean).exp()\n",
    "print(f\"  Mean Ïƒ: {sigma_dist.mean():.3f}\")\n",
    "print(f\"  99th percentile: {torch.quantile(sigma_dist, 0.99):.3f}\")\n",
    "print(f\"  % with Ïƒ > 80: {(sigma_dist > 80).sum().item()/100000*100:.2f}%\")\n",
    "print(\"  âœ… Good coverage for Ïƒ_max=80!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c743797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 39,852,547\n",
      "Training for 200 epochs with LR warmup + cosine decay\n",
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b3905a23c1453b832a4d61933e92ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/200:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 0.1540, LR: 0.000020\n",
      "  âœ¨ New best: 0.1540\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fd98f853834e468d769b826eb231a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/200:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 5: Training Loop\n",
    "# (This cell is correct, using your 200 epochs and LR scheduler)\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 200\n",
    "LEARNING_RATE = 2e-4\n",
    "WARMUP_EPOCHS = 10\n",
    "EMA_DECAY = 0.999\n",
    "MODEL_CKPT = 'pcdiff_cifar10.pth'\n",
    "EMA_CKPT = 'pcdiff_cifar10_ema.pth'\n",
    "\n",
    "# Initialize\n",
    "model = SongUNet(\n",
    "    img_resolution=32,\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    model_channels=128,\n",
    "    channel_mult=[1, 2, 2, 2],\n",
    "    attn_resolutions=[16],\n",
    "    num_blocks=4\n",
    ").to(device)\n",
    "\n",
    "ema = ExponentialMovingAverage(model.parameters(), decay=EMA_DECAY)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# LR scheduler with warmup + cosine decay\n",
    "def lr_lambda(epoch):\n",
    "    if epoch < WARMUP_EPOCHS:\n",
    "        return epoch / WARMUP_EPOCHS\n",
    "    else:\n",
    "        progress = (epoch - WARMUP_EPOCHS) / (EPOCHS - WARMUP_EPOCHS)\n",
    "        return 0.1 + 0.9 * (1 + math.cos(math.pi * progress)) / 2\n",
    "\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Training for {EPOCHS} epochs with LR warmup + cosine decay\")\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "epoch_losses = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_num = epoch + 1\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch_num}/{EPOCHS}\")\n",
    "    \n",
    "    epoch_loss_sum = 0.0\n",
    "    epoch_batch_count = 0\n",
    "    \n",
    "    for x_batch, _ in progress_bar:\n",
    "        x_batch = x_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(model, x_batch)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        ema.update()\n",
    "        \n",
    "        epoch_loss_sum += loss.item()\n",
    "        epoch_batch_count += 1\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f\"{loss.item():.4f}\",\n",
    "            'lr': f\"{scheduler.get_last_lr()[0]:.6f}\"\n",
    "        })\n",
    "    \n",
    "    avg_loss = epoch_loss_sum / epoch_batch_count\n",
    "    epoch_losses.append(avg_loss)\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch_num} - Loss: {avg_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "    \n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        print(f\"  âœ¨ New best: {best_loss:.4f}\")\n",
    "    \n",
    "    if epoch_num % 20 == 0 or epoch_num == EPOCHS:\n",
    "        torch.save(model.state_dict(), MODEL_CKPT)\n",
    "        with ema.average_parameters():\n",
    "            torch.save(model.state_dict(), EMA_CKPT)\n",
    "        print(f\"  ðŸ’¾ Checkpoint saved\")\n",
    "\n",
    "print(f\"\\nâœ… Training complete!\")\n",
    "print(f\"Final loss: {epoch_losses[-1]:.4f}\")\n",
    "print(f\"Best loss: {best_loss:.4f}\")\n",
    "print(f\"Model saved to: {EMA_CKPT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5af924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: âœ… FIXED Sampler - Correct Heun & Broadcasting\n",
    "\n",
    "@torch.no_grad()\n",
    "def edm_wrapper(x, sigma, model):\n",
    "    \"\"\"\n",
    "    EDM denoiser wrapper with preconditioning.\n",
    "    (This wrapper function is correct)\n",
    "    \"\"\"\n",
    "    # sigma is expected to be shape [B]\n",
    "    sigma_view = sigma.view(-1, 1, 1, 1)\n",
    "    \n",
    "    c_skip = 1.0 / (sigma_view ** 2 + 1.0)\n",
    "    c_out = sigma_view / (sigma_view ** 2 + 1.0).sqrt()\n",
    "    c_in = 1.0 / (sigma_view ** 2 + 1.0).sqrt()\n",
    "    \n",
    "    # c_noise needs to be [B] for PositionalEmbedding\n",
    "    c_noise = sigma.log() / 4\n",
    "    \n",
    "    F_x = model(c_in * x, c_noise) # Pass [B] tensor, no .squeeze()\n",
    "    D_theta = c_skip * x + c_out * F_x\n",
    "    return D_theta\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_heun(model, shape, sigmas, device, disable_tqdm=False):\n",
    "    \"\"\"\n",
    "    âœ… CORRECTED: Correct Heun's method + Broadcasting fix.\n",
    "    \"\"\"\n",
    "    from tqdm.auto import tqdm\n",
    "    \n",
    "    x = torch.randn(shape, device=device) * sigmas[0]\n",
    "    \n",
    "    for i in tqdm(range(len(sigmas) - 1), disable=disable_tqdm, desc=\"Sampling\"):\n",
    "        sigma = sigmas[i]\n",
    "        sigma_next = sigmas[i + 1]\n",
    "        dt = sigma_next - sigma\n",
    "        \n",
    "        # --- ðŸ›‘ BUG FIX #2 ðŸ›‘ ---\n",
    "        # We must pass a TENSOR of shape [B] to the wrapper, not a scalar\n",
    "        sigma_tensor = torch.tensor([sigma], device=device).repeat(x.shape[0])\n",
    "        # --- End of Fix ---\n",
    "        \n",
    "        # 1. Predictor step (Euler)\n",
    "        denoised = edm_wrapper(x, sigma_tensor, model)\n",
    "        d = (x - denoised) / sigma\n",
    "        x_next = x + d * dt\n",
    "        \n",
    "        # 2. Corrector step\n",
    "        if sigma_next != 0:\n",
    "            # --- ðŸ›‘ BUG FIX #2 ðŸ›‘ ---\n",
    "            # Must also be applied here\n",
    "            sigma_next_tensor = torch.tensor([sigma_next], device=device).repeat(x.shape[0])\n",
    "            # --- End of Fix ---\n",
    "            \n",
    "            denoised_next = edm_wrapper(x_next, sigma_next_tensor, model)\n",
    "            d_next = (x_next - denoised_next) / sigma_next\n",
    "            \n",
    "            # This Heun update logic IS correct\n",
    "            x = x + (d + d_next) * dt / 2.0 \n",
    "        else:\n",
    "            x = x_next\n",
    "    \n",
    "    return x\n",
    "\n",
    "def get_karras_schedule(K=80, sigma_min=0.002, sigma_max=80.0, rho=7., device='cuda'):\n",
    "    \"\"\"Karras (EDM) noise schedule.\"\"\"\n",
    "    steps = torch.arange(K, device=device, dtype=torch.float32)\n",
    "    sigmas = (sigma_max**(1/rho) + steps/(K-1) * (sigma_min**(1/rho) - sigma_max**(1/rho)))**rho\n",
    "    sigmas = torch.cat([sigmas, torch.tensor([0.0], device=device)])\n",
    "    return sigmas\n",
    "\n",
    "print(\"âœ… Fixed Heun sampler defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8eb41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Generate Sample Grid\n",
    "\n",
    "print(\"Loading trained model for sampling...\")\n",
    "\n",
    "eval_model = SongUNet(\n",
    "    img_resolution=32,\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    model_channels=128,\n",
    "    channel_mult=[1, 2, 2, 2],\n",
    "    attn_resolutions=[16],\n",
    "    num_blocks=4\n",
    ").to(device)\n",
    "\n",
    "# Load the model you just trained\n",
    "eval_model.load_state_dict(torch.load(EMA_CKPT, map_location=device))\n",
    "eval_model.eval()\n",
    "\n",
    "# Generate samples\n",
    "NUM_STEPS = 80\n",
    "GRID_SIZE = 64\n",
    "\n",
    "sigmas = get_karras_schedule(K=NUM_STEPS, sigma_min=0.002, sigma_max=80.0, rho=7.0, device=device)\n",
    "print(f\"Generating {GRID_SIZE} samples with {NUM_STEPS} steps...\")\n",
    "\n",
    "images = sample_heun(\n",
    "    model=eval_model,\n",
    "    shape=(GRID_SIZE, 3, 32, 32),\n",
    "    sigmas=sigmas,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Post-process and save\n",
    "images = (images.clamp(-1, 1) + 1) / 2\n",
    "images = (images * 255).to(torch.uint8)\n",
    "\n",
    "grid = make_grid(images, nrow=8)\n",
    "save_image(grid / 255.0, 'generated_samples_fixed.png')\n",
    "\n",
    "print(f\"\\nâœ… Saved to 'generated_samples_fixed.png'\")\n",
    "print(f\"   Mean: {images.float().mean()/255:.4f}\")\n",
    "print(f\"   Std: {images.float().std()/255:.4f}\")\n",
    "\n",
    "# Display\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(Image.open('generated_samples_fixed.png'))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff7b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: FID Evaluation\n",
    "\n",
    "NUM_FID_IMAGES = 10000 # 50k is standard, but 10k is a good fast check\n",
    "FID_BATCH_SIZE = 128\n",
    "GEN_DIR = \"generated_images_fixed\"\n",
    "\n",
    "if not os.path.exists(GEN_DIR):\n",
    "    os.makedirs(GEN_DIR)\n",
    "\n",
    "print(f\"Generating {NUM_FID_IMAGES} images for FID evaluation...\")\n",
    "\n",
    "num_generated = 0\n",
    "sigmas = get_karras_schedule(K=80, sigma_min=0.002, sigma_max=80.0, rho=7.0, device=device)\n",
    "eval_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    while num_generated < NUM_FID_IMAGES:\n",
    "        batch_size = min(FID_BATCH_SIZE, NUM_FID_IMAGES - num_generated)\n",
    "        \n",
    "        images = sample_heun(\n",
    "            model=eval_model,\n",
    "            shape=(batch_size, 3, 32, 32),\n",
    "            sigmas=sigmas,\n",
    "            device=device,\n",
    "            disable_tqdm=True\n",
    "        )\n",
    "        \n",
    "        images = (images.clamp(-1, 1) + 1) / 2\n",
    "        images = (images * 255).to(torch.uint8)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            img_tensor = images[i].permute(1, 2, 0).cpu().numpy()\n",
    "            img = Image.fromarray(img_tensor)\n",
    "            img.save(os.path.join(GEN_DIR, f\"img_{num_generated + i}.png\"))\n",
    "        \n",
    "        num_generated += batch_size\n",
    "        if num_generated % 1000 == 0:\n",
    "            print(f\"  Generated {num_generated}/{NUM_FID_IMAGES}\")\n",
    "\n",
    "print(\"\\nCalculating FID score...\")\n",
    "\n",
    "try:\n",
    "    fid_score = compute_fid(\n",
    "        fdir1=GEN_DIR,\n",
    "        fdir2=None,\n",
    "        mode=\"clean\",\n",
    "        dataset_name=\"cifar10\",\n",
    "        dataset_res=32,\n",
    "        dataset_split=\"train\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸ† FINAL FID SCORE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n  FID = {fid_score:.2f}\\n\")\n",
    "    print(f\"  Reference (EDM paper): 2.4\")\n",
    "    print(f\"  Your result: {fid_score:.2f}\\n\")\n",
    "    \n",
    "    if fid_score < 10:\n",
    "        print(\"  ðŸŒŸ OUTSTANDING! State-of-the-art quality!\")\n",
    "    elif fid_score < 20:\n",
    "        print(\"  ðŸŽ‰ EXCELLENT! Very good quality!\")\n",
    "    elif fid_score < 30:\n",
    "        print(\"  âœ… GOOD! Solid performance!\")\n",
    "    else:\n",
    "        print(f\"  ðŸ“ˆ Huge improvement! (Was {35.34:.2f})\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ FID calculation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fdccb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
